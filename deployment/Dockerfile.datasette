# This Dockerfile uses docker multi stage build to avoid having big image.
# https://docs.docker.com/build/building/multi-stage/
#
# To build only the "builder" stage, one can do:
# docker build --target=builder --progress=plain -f deployment/Dockerfile.datasette .


FROM python:3.12-slim-bullseye AS builder

WORKDIR /build

RUN apt-get update && \
    apt-get install -y pipenv sqlite3

COPY Pipfile /build/
COPY Pipfile.lock /build/
RUN pipenv install --system --deploy --ignore-pipfile

#  Note: docker caches image building so uncomment and change next line
#  when you change tasks.py or data to make sure they are pulled fresh into image
# RUN echo cache busting!

COPY data /build/data/
COPY tasks.py /build/

RUN invoke create-databases

# -----------------------------------------------------------------------------

FROM python:3.12-slim-bullseye

WORKDIR /datasette
RUN pip install --no-cache datasette==0.64.0 setuptools
COPY --from=builder /build/var/sqlite /datasette/sqlite

EXPOSE 8001
# TODO: remove custom setting when no longer needed
CMD datasette serve --host 0.0.0.0 --port 8001 --cors --inspect-file sqlite/inspect-data.json --metadata sqlite/metadata.json ./sqlite/*.db  --setting max_returned_rows 150000
