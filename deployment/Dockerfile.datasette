# This Dockerfile uses docker multi stage build to avoid having big image.
# https://docs.docker.com/build/building/multi-stage/
#
# To build only the "builder" stage, one can do:
# docker build --target=builder --progress=plain -f deployment/Dockerfile.datasette .

FROM ghcr.io/astral-sh/uv:0.9.26-python3.13-trixie-slim AS uv_setup

WORKDIR /build

RUN apt-get update && \
    apt-get install -y --no-install-recommends sqlite3 curl ca-certificates

# -----------------------------------------------------------------------------

FROM uv_setup AS builder

WORKDIR /build

#  Note: docker caches image building so uncomment and change next line
#  when you change tasks.py or data to make sure they are pulled fresh into image
# RUN echo cache busting!

COPY pyproject.toml .python-version uv.lock tasks.py ./
COPY data /build/data

RUN uv sync --group build --locked

RUN ls -al /build/

RUN uv run invoke create-databases --no-validate-arch=aarch64

# -----------------------------------------------------------------------------

FROM uv_setup

WORKDIR /datasette

COPY pyproject.toml .python-version uv.lock ./

RUN uv sync --locked

COPY --from=builder /build/var/sqlite /datasette/sqlite

EXPOSE 8001
# TODO: remove custom setting when no longer needed
CMD uv run datasette serve --host 0.0.0.0 --port 8001 --cors --inspect-file sqlite/inspect-data.json --metadata sqlite/metadata.json ./sqlite/*.db  --setting max_returned_rows 150000
